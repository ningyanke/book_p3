## 8.Pool 进程池

> 在利用Python进行系统管理的时候，特别是同时操作多个文件目录，或者远程控制多台主机，并行操作可以节约大量的时间。当被操作对象数目不大时，可以直接利用multiprocessing中的Process动态成生多个进程，十几个还好，但如果是上百个，上千个目标，手动的去限制进程数量却又太过繁琐，此时可以发挥进程池的功效。 Pool可以提供指定数量的进程，供用户调用，当有新的请求提交到pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到规定最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来它。
>
> `multiprocessing.Pool` 常用的函数：
>
> | 函数                                  | 解释                                       |
> | ----------------------------------- | ---------------------------------------- |
> | `apply_async(func[,args[,kwargs]])` | 使用非阻塞方式调用func（并行执行，堵塞方式必须等待上一个进程退出才能执行下一个进程），args为传递给func的参数列表，kwds为传递给func的关键字参数列表； |
> | `apply(func[,args[,kwargs]])`       | 使用阻塞的方式调用func                            |
> | `close()`                           | 关闭pool, 使其不在接收新的任务                       |
> | `terninate`                         | 不管任务是否完成,立即终止                            |
> | `join()`                            | 主进程阻塞,等待子进程的退出,必须在close\ terminate 之后使用  |
>
> 

### 同步进程池

> #### `apply_async` 非阻塞方式-进程池:
>
> ```python
> #!/usr/bin/env python
> # coding=utf-8
>
> import multiprocessing
> import time
> import random
> import os
>
>
> def worker(msg):
>     t_start = time.time()
>     print("{} 开始执行, 进程号为 {}".format(msg, os.getpid()))
>     time.sleep(random.random())
>     t_stop = time.time()
>     print('{} 执行完毕,耗时{}'.format(msg, t_stop - t_start))
>
>
> if __name__ == '__main__':
>     # 定义一个进程池,最大为3个进程
>     poll = multiprocessing.Pool(3)
>     for i in range(10):
>         # 这种方式是非阻塞的方式,即一下可以生成3个线程,而不是一个一个的
>         poll.apply_async(worker, (i,))
>
>     print('---start-----')
>     # 进程池关闭
>     poll.close()
>     # 等待所有的进程池中的进程执行完毕
>     poll.join()
>     print('---end-----')
> ```
>
> 执行结果
>
> ```bash
> ---start-----
> 0 开始执行, 进程号为 8423
> 1 开始执行, 进程号为 8424
> 2 开始执行, 进程号为 8425
> 1 执行完毕,耗时0.18147897720336914
> 3 开始执行, 进程号为 8424
> 2 执行完毕,耗时0.4388418197631836
> 4 开始执行, 进程号为 8425
> 0 执行完毕,耗时0.5484819412231445
> 5 开始执行, 进程号为 8423
> 4 执行完毕,耗时0.32697510719299316
> 6 开始执行, 进程号为 8425
> 5 执行完毕,耗时0.2788083553314209
> 7 开始执行, 进程号为 8423
> 6 执行完毕,耗时0.15052056312561035
> 8 开始执行, 进程号为 8425
> 3 执行完毕,耗时0.776545524597168
> 9 开始执行, 进程号为 8424
> 9 执行完毕,耗时0.18672513961791992
> 8 执行完毕,耗时0.44112396240234375
> 7 执行完毕,耗时0.5419049263000488
> ---end-----
> ```
>
> #### `apply` 阻塞的方式进行
>
> ```python
> #!/usr/bin/env python
> # coding=utf-8
>
> import multiprocessing
> import time
> import random
> import os
>
>
> def worker(msg):
>     t_start = time.time()
>     print("{} 开始执行, 进程号为 {}".format(msg, os.getpid()))
>     time.sleep(random.random())
>     t_stop = time.time()
>     print('{} 执行完毕,耗时{}'.format(msg, t_stop - t_start))
>
>
> if __name__ == '__main__':
>     # 定义一个进程池,最大为3个进程
>     poll = multiprocessing.Pool(3)
>     for i in range(10):
>         # 这种方式是阻塞的方式,即进程会一个一个的生成,一个结束会生成另一个
>         poll.apply(worker, (i,))
>
>     print('---start-----')
>     # 进程池关闭
>     poll.close()
>     # 等待所有的进程池中的进程执行完毕
>     poll.join()
>     print('---end-----')
>
> ```
>
> 输出结果
>
> ```python
> 0 开始执行, 进程号为 9366
> 0 执行完毕,耗时0.8929145336151123
> 1 开始执行, 进程号为 9367
> 1 执行完毕,耗时0.7428035736083984
> 2 开始执行, 进程号为 9368
> 2 执行完毕,耗时0.6221437454223633
> 3 开始执行, 进程号为 9366
> 3 执行完毕,耗时0.4575808048248291
> 4 开始执行, 进程号为 9367
> 4 执行完毕,耗时0.32468700408935547
> 5 开始执行, 进程号为 9368
> 5 执行完毕,耗时0.03471636772155762
> 6 开始执行, 进程号为 9366
> 6 执行完毕,耗时0.20032048225402832
> 7 开始执行, 进程号为 9367
> 7 执行完毕,耗时0.8193809986114502
> 8 开始执行, 进程号为 9368
> 8 执行完毕,耗时0.0015950202941894531
> 9 开始执行, 进程号为 9366
> 9 执行完毕,耗时0.4488828182220459
> ---start-----
> ---end-----
> ```

### 异步进程池

> 同步,指的是协同操作,对于A,B,同步可能以为着A需要B的结果作为数据使用,需要协同运行
>
> 异步:各有各的
>
> ```python
> # 异步非阻塞进程池,并使用get得到异步的结果
> #!/usr/bin/env python
> # coding=utf-8
>
> import multiprocessing
> import time
>
>
> def foo1(i):
>     time.sleep(2)
>     return i + 100
>
>
> def bar(arg):
>     return arg
>
>
> if __name__ == '__main__':
>     res_list = []
>     t_start = time.time()
>     pool = multiprocessing.Pool(5)
>     for i in range(10):
>         # 使用了关键字 func
>         # func的结果(return) 成为了回调函数的出入参数
>         res = pool.apply_async(func=foo1, args=(i,), callback=bar)
>         res_list.append(res)
>
>     # 关闭进程池
>     pool.close()
>
>     # 阻塞直到进程池中的进程全部结束
>     pool.join()
>     # 输出得到的结果
>     for res in res_list:
>         print(res.get())
>     t_end = time.time()
>     print('the program time is {}'.format(t_end - t_start))
>
> ```
>
> 注意,`func ` 产生的结果,作为了回调函数的参数

### 进程池中间调用Queue队列

> 如果是进程池,不能直接调用`multiprocessing.Queue` ,而应该调用`multiprocessing.Manager().Queue`
>
> Manager是一个高级模块,不谈论其他,只看一下实现的队列的问题.
>
> ```python
> #!/usr/bin/env python
> # coding=utf-8
>
> import multiprocessing
> import time
> import os
> import random
>
> # 写数据 进程执行的代码
>
>
> def write(q):
>     print('write启动{}, 父进程为{}'.format(os.getpid(), os.getppid()))
>     for i in ["Python", 'C', 'Java']:
>         q.put(i)
>
>
> # 读数据 进程执行的代码
>
>
> def read(q):
>     print('read启动{}, 父进程为{}'.format(os.getpid(), os.getppid()))
>     for i in range(q.qsize()):
>         msg = q.get(True)
>         print("取出{}".format(msg))
>
>
> if __name__ == '__main__':
>
>     # 使用manager中的Queue 来初始化
>     q = multiprocessing.Manager().Queue()
>     # 创建一个进程池
>     po = multiprocessing.Pool()
>     # 使用阻塞的方式来创建进程,这样就不需要设置死循环了,可以让witer完全执行完后
>     # 在由reader去读取
>     po.apply(write, (q,))
>     po.apply(read, (q,))
>     # close 必须在前面
>     po.close()
>     po.join()
>     print("{} End".format(os.getpid()))
>
> ```
>
> 执行结果
>
> ```python
> write启动21287, 父进程为21280
> read启动21291, 父进程为21280
> 取出Python
> 取出C
> 取出Java
> 21280 End
> ```